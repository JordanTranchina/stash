# Technical Specification: Listen Later (AI Podcast)

## Overview

Automated pipeline to convert "Stashed" articles into a conversational AI podcast. **Core Philosophy:** "Software for One" â€“ highly personalized, leveraging serverless/cloud-native tools where possible, but using robust compute (GitHub Actions) for heavy media processing.

## Architecture

### Components

1.  **Data Source:** Supabase `articles` table.
2.  **Orchestrator & Compute:** GitHub Actions (Cron + Manual Workflow Dispatch).
    - _Why Actions?_ Free runtime, pre-installed `ffmpeg`, no execution timeout issues like Vercel Serverless (10s-60s limit), easy to schedule.
3.  **Intelligence:**
    - **Scripting:** **Gemini 1.5 Flash (Free Tier)**.
      - _Cost:_ Free (up to 15 RPM).
      - _Performance:_ Sufficient context window (1M) and reasoning for script generation.
    - **TTS:** **Edge TTS (`edge-tts` python lib)**.
      - _Cost:_ Free (uses MS Edge Read Aloud API).
      - _Quality:_ High-quality neural voices (e.g., `en-US-AndrewNeural`, `en-US-AvaNeural`).
      - _Fallback:_ Open Source **Kokoro-82M** (ONNX) running locally on the Runner (if edge-tts breaks).
4.  **Storage:** Supabase Storage (`podcast-media` bucket).
5.  **Distribution:** Next.js API Route (Vercel) to serve `rss.xml`.

### Data Flow

1.  **Trigger:** Scheduled Cron (Morning) OR Manual User Trigger (Action Dispatch).
2.  **Extract (Issue #6):** Runner fetches "Unarchived" & "Recent" articles from Supabase.
3.  **Script (Issue #7):** Runner sends text to Gemini 1.5 Flash $\rightarrow$ Receives JSON Dialogue (Alex/Taylor).
4.  **Audio Gen (Issue #8):** Runner iterates JSON $\rightarrow$ Calls `edge-tts` CLI/Lib $\rightarrow$ Saves temp `.mp3` clips.
5.  **Assembly (Issue #9):** Runner uses `ffmpeg` to concat clips + intro/outro music $\rightarrow$ `episode.mp3`.
6.  **Publish (Issue #10):**
    - Upload `episode.mp3` to Supabase Storage.
    - Update `podcast_episodes` table (new table needed) with metadata.
7.  **Serve:** Podcast Player requests RSS URL $\rightarrow$ Vercel API reads `podcast_episodes` $\rightarrow$ Returns XML.

## Implementation Details

### 1. Database Schema (Supabase)

New table: `podcast_episodes`

- `id` (uuid)
- `created_at` (timestamptz)
- `title` (text)
- `description` (text) (Show notes: generated by LLM)
- `audio_url` (text)
- `duration_seconds` (int)
- `size_bytes` (int)
- `related_article_ids` (uuid[], FK to articles)

### 2. The Pipeline Script (Python)

_Decision: Switch to Python for the heavy lifting script. Python has better support for `edge-tts` and media handling._

#### Step 1: Data Extraction (#6)

- Query: `SELECT * FROM articles WHERE status = 'saved' AND created_at > NOW() - INTERVAL '7 days'` (or similar logic).
- _Constraint:_ Limit to top 5 articles to manage context window and audio length.

#### Step 2: Vibe Engine / Scripting (#7)

- **Model:** `gemini-1.5-flash` (via `google-generativeai` lib).
- **System Prompt:** "You are the producers Alex and Taylor..."
- **Input:** JSON list of article content.
- **Output:** JSON array of lines: `[{ "speaker": "Alex", "text": "..." }, { "speaker": "Taylor", "text": "..." }]`.

#### Step 3: Audio Generation (#8)

- **Library:** `edge-tts`
- **Voices:**
  - **Alex:** `en-US-AndrewNeural` (Confident, male)
  - **Taylor:** `en-US-AvaNeural` (Friendly, female)
- **Process:** Generate individual clips for each dialogue line.

#### Step 4: Assembly (#9)

- Use `ffmpeg` (subprocess calls).
- Command: `ffmpeg -f concat -i filelist.txt -c copy output.mp3`
- _Advanced (#14):_ Add chapter markers using ffmpeg metadata flags during encoding.

### 3. RSS Feed (#10)

- **Endpoint:** `/api/podcast/rss`
- **Logic:**
  1. Fetch last 10 entries from `podcast_episodes`.
  2. Generate XML using `rss` package.
  3. Set headers: `Content-Type: application/rss+xml`.
- **Cache Control:** `s-maxage=3600` (1 hour).

## Security & Config

- **Secrets:** stored in GitHub Repository Secrets (SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY, GEMINI_API_KEY).
- **Triggers:**
  - `on: schedule` (cron: '0 12 \* \* \*' -> 7am EST)
  - `on: workflow_dispatch` (for On-Demand #12)

## Task Mapping

- **#6 Data Extraction:** Create Python script to query Supabase.
- **#7 Scriptwriting:** Integrate `google-generativeai`.
- **#8 Audio Gen:** Integrate `edge-tts`.
- **#9 Assembly:** Python script to manage FFMPEG calls.
- **#10 RSS:** Vercel API Route implementation.
